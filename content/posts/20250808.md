---
title: "SmolDocling notes"
date: 2025-08-08T16:42:36+02:00
draft: false
tags: []
categories: []
ShowToc: false
cover:
  image: ""   # change to your image path in /static/images/
  alt: "Cover image"
  caption: "Optional caption for the cover image."
  relative: false
math: true
---

## Introduction
OCR on documents remains a challenging task. While printed text can often be recognized with 95% or higher accuracy, real-world documents — containing handwriting, non-standard layouts, and other irregularities — are still much harder to read accurately. There are high quality systems solving documents reading in sub-tasks: OCR, layout analysis, structure recognition, classification.  
Recent trend is using large vision-language models to solve whole convertion task in one shot, and giving the user opportunity to define additional specific tasks to do in the prompt. 
This post is about SmalDocling, a very tiny and compute-effient vision-language model doing the convertion task and the instruction task written into a prompt. The post is based on SmolDocling [research paper](https://arxiv.org/abs/2503.11576) along with some personal experiences from working with it.


## Architecture
SmolDocling model comes from family of Hugging Face's SmolVLM. It was trained on datasets allowing for recognition of captions, charts, forms, code, equations, tables, footnotes, lists, page footers & headers, section headings, and text. SmolDocling does OCR on elements mentioned and recognizes the type and location. And here we have main task of SmolDocling - conversion and docuemnt understatning.

<img src="/images/0001.jpg" alt="Sample" width="800">

A read cube named as Vision Encoder on the architeture is the image encoder used in SomlVM models, SigLIP-base path-16/512 (93M). It comes from Google’s CLIP-style image encoders — replacing CLIP’s contrastive softmax loss with a sigmoid cross-entropy loss (this change makes training more stable and more accurate when matching images and text). It's superpower is low-memory and fast inference in multimodal reasoning tasks.  


## Usage
Obviously we can get bigger SmolDocling model (), or large vision-language models to quickly get higher accuracy but also slower inference and bigger compute usage. 
SmolDocling can find it's niche for deployments on edge or resource-constrained devices. Another usage is quick prototyping and  experimentation, it's always better to start with small and quick models.  

To be continued....


[read the memory usage during inference is it below or above 1 GB?]

## DocTags


## Pre-training datasets


## Task-specific datasets

## Experiments
