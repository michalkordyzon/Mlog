<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Michal’s Log</title><link>https://mlog.space/posts/</link><description>Recent content in Posts on Michal’s Log</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 08 Aug 2025 16:42:36 +0200</lastBuildDate><atom:link href="https://mlog.space/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>SmolDocling notes</title><link>https://mlog.space/posts/smoldocling-notes/</link><pubDate>Fri, 08 Aug 2025 16:42:36 +0200</pubDate><guid>https://mlog.space/posts/smoldocling-notes/</guid><description>Introduction OCR on documents remains a challenging task. While printed text can often be recognized with 95% accuracy or higher, real-world documents — containing handwriting, non-standard layouts, and other irregularities — are still much harder to read accurately.
This post is a summary of the SmolDocling research paper along with some personal experiences from working with it.
Architecture SmalDocling model comes from family of Hugging Face&amp;rsquo;s SmolVLM. It was trained on datasets allowing for recognition of captions, charts, forms, code, equations, tables, footnotes, lists, page footers &amp;amp; headers, section headings, and text.</description></item></channel></rss>